{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import Input, layers, Model, Sequential\nimport tensorflow_datasets as tfds\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport re\nimport sys","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Setup"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def connect_to_tpu():\n\n    try: # detect TPUs\n        resolver = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n        print(\"Running on TPU  \", resolver.master())\n    except ValueError: # detect GPUs\n        resolver = None\n\n    if resolver:\n        tf.config.experimental_connect_to_cluster(resolver)\n        tf.tpu.experimental.initialize_tpu_system(resolver)\n        print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n        strategy = tf.distribute.experimental.TPUStrategy(resolver)\n\n    else:\n        strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n        #strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n        #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n    \n    return strategy\n\n\nstrategy = connect_to_tpu()\n\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get google storage bucket\n\n#set these credentials after initializing tpu\nfrom kaggle_datasets import KaggleDatasets\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nuser_credential = user_secrets.get_gcloud_credential()\nuser_secrets.set_tensorflow_credential(user_credential)\n\n# Then get the google bucket path\nGCS_DS_PATH = KaggleDatasets().get_gcs_path() # you can list the bucket with \"!gsutil ls $GCS_DS_PATH\"\n\nprint(GCS_DS_PATH)\n\n#Do not use this path to load tfrecords '../input/enpt10000/train.tfrecord'\n#instead use tf.io.gfile.glob(GCS_DS_PATH+'/train.tfrecord')\n\n#https://www.kaggle.com/philculliton/a-simple-tf-2-1-notebook\n#very useful notebook on using TPUs\n\n#https://www.tensorflow.org/datasets/gcs\n#using tfds with TPUs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare flower datset"},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 16 * strategy.num_replicas_in_sync\nEPOCHS = 10\nLEARNING_RATE = 3e-5 * strategy.num_replicas_in_sync\nHEIGHT = 512\nWIDTH = 512\nCHANNELS = 3\nN_CLASSES = 104\nseed = 101\n\nfolder = f\"/tfrecords-jpeg-{HEIGHT}x{WIDTH}\"\ntrain_files = tf.io.gfile.glob(GCS_DS_PATH + folder + '/train/*.tfrec')\ntest_files =tf.io.gfile.glob(GCS_DS_PATH + folder + '/test/*.tfrec')\nval_files =tf.io.gfile.glob(GCS_DS_PATH + folder + '/val/*.tfrec')\n\n\n# Datasets utility functions\nAUTO = tf.data.experimental.AUTOTUNE # instructs the API to read from multiple files if available.\n\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.reshape(image, [HEIGHT, WIDTH, 3])\n    return image\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.cast(example['class'], tf.int32)\n    return image, label\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    idnum = example['id']\n    return image, idnum # returns a dataset of image(s)\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) \n    if labeled:\n        dataset = dataset.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n    else:\n        dataset = dataset.map(read_unlabeled_tfrecord,  num_parallel_calls=AUTO)\n    return dataset\n\ndef data_augment(image, label):\n    p_spatial = tf.random.uniform([1], minval=0, maxval=1, dtype='float32', seed=seed)\n    p_spatial2 = tf.random.uniform([1], minval=0, maxval=1, dtype='float32', seed=seed)\n    p_pixel = tf.random.uniform([1], minval=0, maxval=1, dtype='float32', seed=seed)\n    p_crop = tf.random.uniform([1], minval=0, maxval=1, dtype='float32', seed=seed)\n    \n    ### Spatial-level transforms\n    if p_spatial >= .2: # flips\n        image = tf.image.random_flip_left_right(image, seed=seed)\n        image = tf.image.random_flip_up_down(image, seed=seed)\n        \n    if p_crop >= .7: # crops\n        if p_crop >= .95:\n            image = tf.image.random_crop(image, size=[int(HEIGHT*.6), int(WIDTH*.6), CHANNELS], seed=seed)\n        elif p_crop >= .85:\n            image = tf.image.random_crop(image, size=[int(HEIGHT*.7), int(WIDTH*.7), CHANNELS], seed=seed)\n        elif p_crop >= .8:\n            image = tf.image.random_crop(image, size=[int(HEIGHT*.8), int(WIDTH*.8), CHANNELS], seed=seed)\n        else:\n            image = tf.image.random_crop(image, size=[int(HEIGHT*.9), int(WIDTH*.9), CHANNELS], seed=seed)\n        image = tf.image.resize(image, size=[HEIGHT, WIDTH])\n    \n    ## Pixel-level transforms\n    if p_pixel >= .4: # pixel transformations\n        if p_pixel >= .85:\n            image = tf.image.random_saturation(image, lower=0, upper=2, seed=seed)\n        elif p_pixel >= .65:\n            image = tf.image.random_contrast(image, lower=.8, upper=2, seed=seed)\n        elif p_pixel >= .5:\n            image = tf.image.random_brightness(image, max_delta=.2, seed=seed)\n        else:\n            image = tf.image.adjust_gamma(image, gamma=.6)\n\n    return image, label\n\ndef get_training_dataset(filenames):\n    dataset = load_dataset(filenames, labeled=True)\n    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    dataset = dataset.cache()\n    dataset = dataset.shuffle(1000000)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_validation_dataset(filenames):\n    dataset = load_dataset(filenames, labeled=True)\n    dataset = dataset.cache()\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef get_test_dataset(filenames):\n    dataset = load_dataset(filenames, labeled=True)\n    dataset = dataset.cache()\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef count_data_items(filenames):\n    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\ndef int_div_round_up(a, b):\n    return (a + b - 1) // b","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train data\nNUM_TRAINING_IMAGES = count_data_items(train_files)\ntrain_ds = get_training_dataset(train_files)\n\n# Val data\nNUM_TEST_IMAGES = count_data_items(test_files)\nval_ds = get_test_dataset(val_files)\n\n# Test data\nNUM_TEST_IMAGES = count_data_items(test_files)\ntest_ds = get_test_dataset(test_files)\n\ntrain_dist_ds = strategy.experimental_distribute_dataset(train_ds)\nval_dist_ds = strategy.experimental_distribute_dataset(val_ds)\ntest_dist_ds = strategy.experimental_distribute_dataset(test_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#May be slow since we are caching it the first time\n\n\ntfds.core.benchmark(train_dist_ds)\ntfds.core.benchmark(val_dist_ds)\n#tfds.core.benchmark(test_dist_ds)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Strategy, Training loops & Validation functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"#model, optimizer, metrics must be inside strategy scope\nwith strategy.scope():\n    \n    base_model = tf.keras.applications.VGG16(include_top=False, weights='imagenet',input_shape=(512,512,3))\n    \n    for layer in base_model.layers[:-3]:\n        layer.trainable = False\n    \n    model = Sequential([base_model,\n                        layers.GlobalMaxPool2D(),\n                        layers.Dense(N_CLASSES)])\n    \n    optimizer = tf.keras.optimizers.Adam(0.01)\n    \n    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n            from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n\n    def loss_function(labels, preds):\n        per_example_loss = loss_object(labels, preds)\n        return tf.nn.compute_average_loss(per_example_loss, global_batch_size= BATCH_SIZE)\n    \n    train_loss = tf.keras.metrics.Mean('training_loss', dtype=tf.float32)\n    train_acc = tf.keras.metrics.SparseCategoricalAccuracy('training_acc', dtype=tf.float32)\n    test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n    test_acc = tf.keras.metrics.SparseCategoricalAccuracy('test_acc', dtype=tf.float32)\n    \n    #checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)\n    \n\n\ndef forward_pass(ds_chunk):\n    inputs, labels = ds_chunk\n    preds = model(inputs)\n    return preds, labels\n\n@tf.function\ndef multiple_dist_train_steps(dist_iter, steps):\n    def _train_step(ds_chunk):\n        with tf.GradientTape() as tape:\n            preds, labels = forward_pass(ds_chunk)\n            loss_val = loss_function(labels, preds)\n        gradients = tape.gradient(loss_val, model.trainable_variables) \n        optimizer.apply_gradients(zip(gradients, model.trainable_variables),\n                                     experimental_aggregate_gradients=True)\n        train_loss.update_state(loss_val * strategy.num_replicas_in_sync)\n        train_acc.update_state(labels, preds)\n    \n    for _ in tf.range(steps):\n        optional_data = dist_iter.get_next_as_optional()\n        if not optional_data.has_value():\n            break\n        strategy.run(_train_step, args=(optional_data.get_value(),))\n        # tf.print(strategy.experimental_local_results(per_replica_results))\n\n@tf.function\ndef dist_train_epoch(ds):\n     #https://www.tensorflow.org/tutorials/distribute/custom_training#iterating_inside_a_tffunction\n    def _train_step(ds_chunk):\n        with tf.GradientTape() as tape:\n            preds, labels = forward_pass(ds_chunk)\n            loss_val = loss_function(labels, preds)\n        gradients = tape.gradient(loss_val, model.trainable_variables) \n        optimizer.apply_gradients(zip(gradients, model.trainable_variables),\n                                 experimental_aggregate_gradients=True)\n      \n        train_loss.update_state(loss_val * strategy.num_replicas_in_sync)\n        train_acc.update_state(labels, preds)\n    for chunk in ds:\n        strategy.run(_train_step, args = (chunk,))\n\n@tf.function\ndef multiple_dist_test_steps(dist_iter, steps):\n    def _test_step(ds_chunk):\n        preds, labels = forward_pass(ds_chunk)\n        loss_val = loss_function(labels, preds)\n        test_loss.update_state(loss_val * strategy.num_replicas_in_sync)\n        test_acc.update_state(labels, preds)\n\n    for _ in tf.range(steps):\n        optional_data = dist_iter.get_next_as_optional()\n        if not optional_data.has_value():\n            break\n        strategy.run(_test_step, args=(optional_data.get_value(),))\n\n\n@tf.function\ndef dist_test_epoch(ds):\n     #https://www.tensorflow.org/tutorials/distribute/custom_training#iterating_inside_a_tffunction\n    def _test_step(ds_chunk):   \n        preds, labels = forward_pass(ds_chunk)\n        loss_val = loss_function(labels, preds)\n        test_loss.update_state(loss_val * strategy.num_replicas_in_sync)\n        test_acc.update_state(labels, preds)\n\n    for chunk in ds:\n        strategy.run(_test_step, args = (chunk,))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iter(train_dist_ds).get_next_as_optional()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from time import time\n\n# start = int(round(time() * 1000))\n# multiple_dist_train_steps(iter(train_dist_ds), 100)\n# end_ = int(round(time() * 1000)) - start\n# print(end_)\n\nstart = int(round(time() * 1000))\ndist_train_epoch(train_dist_ds)\nend_ = int(round(time() * 1000)) - start\nprint(end_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loss.reset_states()\ntrain_acc.reset_states()\ntest_loss.reset_states()\ntest_acc.reset_states()\n\nepochs = 10\n\n# batches_in_train_ds = sum([1 for i in train_dist_ds])\n# batches_in_val_ds = sum([1 for i in val_dist_ds])\n# print(batches_in_train_ds)\n# print(batches_in_val_ds)\n\ntrain_losses = []\nval_losses = []\ntrain_accuracies = []\nval_accuracies = []\n\nfor epoch in range(epochs):\n    dist_train_epoch(train_dist_ds)\n    dist_test_epoch(val_dist_ds)\n    \n    train_losses.append(train_loss.result())\n    train_accuracies.append(train_acc.result())\n    val_losses.append(test_loss.result())\n    val_accuracies.append(test_acc.result())\n    \n    sys.stdout.write(f\"\\rEpoch {epoch+1}  train_loss: {train_loss.result():.3f}  train_acc: {train_acc.result():.3f}    val_loss: {test_loss.result():.3f}    val_acc: {test_acc.result():.3f}\")\n    \n    train_loss.reset_states()\n    train_acc.reset_states()\n    test_loss.reset_states()\n    test_acc.reset_states()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def round_fn(x):\n    return list(map(lambda item: round(item.numpy(),3), x))\n\n\n\nimport matplotlib.pyplot as plt\n\nfig, (ax1,ax2) = plt.subplots(1,2, figsize = (10,5))\n\nx = list(range(1,epochs+1))\n\nax1.plot(x, round_fn(train_losses),'--ro')\nax1.plot(x, round_fn(val_losses),'--bo')\n\nax2.plot(x, round_fn(train_accuracies),'--r+')\nax2.plot(x, round_fn(val_accuracies),'--b+')\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}